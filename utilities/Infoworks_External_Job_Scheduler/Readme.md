# Infoworks External Job Scheduler

## Introduction

Infoworks External Job Scheduler is a Python script that triggers various types of infoworks jobs, monitors their progress, and returns their status. 
It is designed to be flexible and customizable, allowing users to integrate with any external schedulers like Tivoli, Tidal etc.

## Table of Contents
- [Introduction](#introduction)
- [Features](#features)
- [Prerequisites](#prerequisites)
- [Installation](#installation)
- [Setup](#setup)
- [Usage](#usage)
  - [Trigger Workflow](#trigger-workflow)
  - [Trigger Table Ingestion](#trigger-table-ingestion)
  - [Trigger Table Group Ingestion](#trigger-table-group-ingestion)
  - [Trigger Pipeline](#trigger-pipeline)
  - [Trigger Pipeline Group](#trigger-pipeline-group)
- [Output](#output)
- [Authors](#authors)


## Features
* Triggers and monitors various Infoworks jobs.
  * Workflow
  * Table Ingestion
  * Table Group Ingestion
  * Pipeline
  * Pipeline Group
* Provides detailed job summary and cluster log path information for the failed jobs to help the operational team to troubleshoot hte issues / failures.
* Exit codes customization for different job statuses.


## Prerequisites
* Python 3.6
* Infoworks 5.3.x (not compatible with earlier version of Infoworks)
* Infoworks User with Admin Privileges to use Workflow feature.

## Installation
It is recommended to set up a virtual environment and install the required dependencies. 
Below are the commands to do it:

1. Download Job_Executor.py and config.ini to your local machine and move them into infoworks_job_master directory.
2. Navigate to the project directory:
    ```
    cd infoworks_job_master
    ```
3. Create a new virtual environment using venv:
    ```
    python3 -m venv infoworks_job_master_env
    ```
4. Activate the virtual environment:
    ```
    source infoworks_job_master_env/bin/activate
    ```
5. Install the required packages using pip and the requirements.txt file:
    ```
    pip install -r requirements.txt
    ```
   
## Setup
Before using the project, Set up the configuration file.
Update config.ini with the infoworks environment details and any other default values if required.

**config.ini**
```
[INFOWORKS_ENVIRONMENT]

HOST = < IP Address of Infoworks VM >
PROTOCOL = < http/https >
PORT = < 443 for https / 3000 for http >
REFRESH_TOKEN = < Refresh Token from Infoworks Account >

[JOB_RUN_SETTINGS]

POLL_TIME = < Poll Time in seconds to fetch status of the job >
REQUEST_TIME_OUT = < Time in seconds to timeout an API request >
MAX_RETRIES = <Max Retries before raising an exception>

[LOGGING]

LOG_FOLDER = < Default log folder for log files >
LOG_LEVEL = < DEBUG/ INFO / WARNING / ERROR / CRITICAL >

[EXIT_CODES]

SUCCESS_JOB_COMPLETED = < Process Success, Job Success > 
ERROR_ABRUPT_FAILURE = < Process Failure >
TABLE_INGESTION_FAILURE = < Process Success, Table Ingestion Job Failure >
TABLE_GROUP_INGESTION_FAILURE = < Process Success, Table Group Ingestion Job Failure >
WORKFLOW_FAILURE = < Process Success, Workflow Job Failure >
PIPELINE_FAILURE = < Process Success, Pipeline Job Failure >
PIPELINE_GROUP_FAILURE = < Process Success, Pipeline Group Job Failure >
```


## Usage
```
python3 Job_Executor.py [workflow, table_ingestion, table_group_ingestion, pipeline, pipeline_group] [MODE SUB_ARGUMENTS]
```
The script can be used in five modes i.e, workflow, table_ingestion, table_group_ingestion, pipeline, pipeline_group to trigger respective
type of Jobs.

### Trigger Workflow

```
python3 Job_Executor.py workflow --config_folder <config.ini folder_path> --workflow_name <workflow_name> --domain_name <domain_name> --poll_time <poll_time> --logs_folder <logs_folder_location>
```

#### Input Arguments

| **Parameter**    | **Description**                                                                                                                           |
|:-----------------|:------------------------------------------------------------------------------------------------------------------------------------------|
| `config_folder`* | Folder Location of config.ini                                                                                                             |
| `workflow_name`* | Infoworks Workflow Name to be executed                                                                                                    |
| `domain_name`*   | Infoworks Domain Name of the workflow to be executed.                                                                                     |
 | `poll_time`      | Polling time interval (in seconds) to retrieve status. If argument is not passed, default poll_time is used from config.ini file.         |
| `logs_folder`    | Folder to store logs generated by the script. If argument is not passed, default poll_time is used from config.ini file.                  |

**All Parameters marked with * are Required**


### Trigger Table Ingestion

```
python3 Job_Executor.py table_ingestion --config_folder <config.ini folder_path> --source_name <source_name> --environment_name  <environment_name> --compute_name <compute_name> --table_names <Individual/ Comma Seperated Table Names> --job_type <job_type> --poll_time <poll_time> --logs_folder <logs_folder_location>
```

#### Input Arguments

| **Parameter**       | **Description**                                                                                                                          |
|:--------------------|:-----------------------------------------------------------------------------------------------------------------------------------------|
| `config_folder`*    | Folder Location of config.ini                                                                                                            |
| `source_name`*      | Infoworks Source Name of the tables to be ingested                                                                                       |
| `environment_name`* | Infoworks Data Environment Name of the compute where the job has to be executed                                                          |
 | `compute_name`*     | Infoworks Compute Name in the Data Environment where the job has to be executed                                                          |
 | `table_names`*      | Comma Separated Infoworks Table Names to be ingested                                                                                     |
 | `job_type`          | Table Ingestion Job Type [cdc_merge, truncate_reload]. Default Job Type is truncate_reload                                               |
 | `poll_time`         | Polling time interval (in seconds) to retrieve status. If argument is not passed, default poll_time is used from config.ini file         |
| `logs_folder`       | Folder to store logs generated by the script. If argument is not passed, default poll_time is used from config.ini file.                 |

**All Parameters marked with * are Required**

### Trigger Table Group Ingestion

```
python3 Job_Executor.py table_group_ingestion --config_folder <config.ini folder_path> --source_name <source_name> --table_group_name <table_group_name> --job_type <job_type> --poll_time <poll_time>  --logs_folder <logs_folder_location>
```

#### Input Arguments

| **Parameter**       | **Description**                                                                                                                          |
|:--------------------|:-----------------------------------------------------------------------------------------------------------------------------------------|
| `config_folder`*    | Folder Location of config.ini                                                                                                            |
| `source_name`*      | Infoworks Source Name of the table group to be ingested                                                                                  |
| `table_group_name`* | Infoworks Table Group Name to be ingested                                                                                                |
 | `job_type`          | Table Ingestion Job Type [cdc_merge, truncate_reload]. Default Job Type is truncate_reload                                               |
 | `poll_time`         | Polling time interval (in seconds) to retrieve status. If argument is not passed, default poll_time is used from config.ini file         |
| `logs_folder`       | Folder to store logs generated by the script. If argument is not passed, default poll_time is used from config.ini file.                 |

**All Parameters marked with * are Required**

### Trigger Pipeline 

```
python3 Job_Executor.py pipeline --config_folder <config.ini folder_path> --domain_name <domain_name> --pipeline_name <pipeline_name>  --poll_time <poll_time>  --logs_folder <logs_folder_location>
```

#### Input Arguments

| **Parameter**    | **Description**                                                                                                                          |
|:-----------------|:-----------------------------------------------------------------------------------------------------------------------------------------|
| `config_folder`* | Folder Location of config.ini                                                                                                            |
| `domain_name`*   | Infoworks Domain Name of the pipeline to be executed                                                                                     |
| `pipeline_name`* | Infoworks Pipeline Name to be executed                                                                                                   |
 | `poll_time`      | Polling time interval (in seconds) to retrieve status. If argument is not passed, default poll_time is used from config.ini file         |
| `logs_folder`    | Folder to store logs generated by the script. If argument is not passed, default poll_time is used from config.ini file.                 |

**All Parameters marked with * are Required**

### Trigger Pipeline Group

```
python3 Job_Executor.py pipeline_group --config_folder <config.ini folder_path> --domain_name <domain_name> --pipeline_group_name <pipeline_group_name>  --poll_time <poll_time>  --logs_folder <logs_folder_location>
```

#### Input Arguments

| **Parameter**          | **Description**                                                                                                                          |
|:-----------------------|:-----------------------------------------------------------------------------------------------------------------------------------------|
| `config_folder`*       | Folder Location of config.ini                                                                                                            |
| `domain_name`*         | Infoworks Domain Name of the pipeline group to be executed                                                                               |
| `pipeline_group_name`* | Infoworks Pipeline Group Name to be executed                                                                                             |
 | `poll_time`            | Polling time interval (in seconds) to retrieve status. If argument is not passed, default poll_time is used from config.ini file         |
| `logs_folder`          | Folder to store logs generated by the script. If argument is not passed, default poll_time is used from config.ini file.                 |

**All Parameters marked with * are Required**


## Output
The script creates a **/logs/{mode}** folder and store the log 
of each run with the below_filename convention <br>

IWX_JM_WorkflowRun_{domain_name}\_{workflow_name}\_{current_time}.log <br>
IWX_JM_TableIngestionRun\_{source_name}\_{current_time}.log <br>
IWX_JM_TableGroupIngestionRun_{source_name}\_{table_group_name}\_{current_time}.log <br>
IWX_JM_PipelineRun\_{pipeline_name}\_{current_time}.log <br>
IWX_JM_PipelineGroupRun\_{pipeline_group_name}\_{current_time}.log <br>

Sample output files are available in /Sample_Outputs/ directory.

## Authors

* Ismail Mohammed
* Sanath Singavarapu
